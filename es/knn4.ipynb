{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##### Copyright 2020 Los autores de TensorFlow."
      ],
      "metadata": {
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [

      ],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "metadata": {
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Recurrent Neural Networks (RNN) with Kerast"
      ],
      "metadata": {
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introducción\n",
        "\n",
        "Recurrent neural networks (RNN) are a class of neural networks that is powerful for modeling sequence data such as time series or natural language.\n",
        "\n",
        "Nuevo párrafo.\n",
        "\n",
        "Schematically, a RNN layer uses a `for` loop to iterate over the timesteps of a sequence, while maintaining an internal state that encodes information about the timesteps it has seen so far.\n",
        "\n",
        "La API Keras RNN está diseñada con un enfoque en:\n",
        "\n",
        "- **Facilidad de uso** : las capas integradas `keras.layers.RNN` , `keras.layers.LSTM` , `keras.layers.GRU` le permiten crear rápidamente modelos recurrentes sin tener que tomar decisiones de configuración difíciles.\n",
        "\n",
        "- **Facilidad de personalización** : también puede definir su propia capa de celdas RNN (la parte interna del bucle `for` ) con un comportamiento personalizado y usarla con la capa genérica `keras.layers.RNN` (el bucle `for` mismo). Esto le permite crear rápidamente prototipos de diferentes ideas de investigación de forma flexible con un código mínimo."
      ],
      "metadata": {
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configuración"
      ],
      "metadata": {
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [

      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Capas RNN incorporadas: un ejemplo simple"
      ],
      "metadata": {
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hay tres capas RNN integradas en Keras:\n",
        "\n",
        "1. `keras.layers.SimpleRNN` , un RNN completamente conectado donde la salida del paso de tiempo anterior se alimentará al próximo paso de tiempo.\n",
        "\n",
        "2. `keras.layers.GRU` , propuesto por primera vez en [Cho et al., 2014](https://arxiv.org/abs/1406.1078) .\n",
        "\n",
        "3. `keras.layers.LSTM` , propuesto por primera vez en [Hochreiter &amp; Schmidhuber, 1997](https://www.bioinf.jku.at/publications/older/2604.pdf) .\n",
        "\n",
        "A principios de 2015, Keras tuvo las primeras implementaciones Python de código abierto reutilizables de LSTM y GRU.\n",
        "\n",
        "Aquí hay un ejemplo simple de un modelo `Sequential` que procesa secuencias de números enteros, incorpora cada número entero en un vector de 64 dimensiones y luego procesa la secuencia de vectores usando una capa `LSTM` ."
      ],
      "metadata": {
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [

      ],
      "source": [
        "model = keras.Sequential()\n",
        "# Add an Embedding layer expecting input vocab of size 1000, and\n",
        "# output embedding dimension of size 64.\n",
        "model.add(layers.Embedding(input_dim=1000, output_dim=64))\n",
        "\n",
        "# Add a LSTM layer with 128 internal units.\n",
        "model.add(layers.LSTM(128))\n",
        "\n",
        "# Add a Dense layer with 10 units.\n",
        "model.add(layers.Dense(10))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los RNN incorporados admiten una serie de características útiles:\n",
        "\n",
        "- Abandono `recurrent_dropout` , a través de los argumentos `dropout` y abandono_recurrente\n",
        "- Capacidad para procesar una secuencia de entrada a la inversa, a través del argumento `go_backwards`\n",
        "- Desenrollado de bucles (lo que puede conducir a una gran aceleración al procesar secuencias cortas en la CPU), a través del argumento de `unroll`\n",
        "- ...y más.\n",
        "\n",
        "Para obtener más información, consulte la [documentación de la API de RNN](https://keras.io/api/layers/recurrent_layers/) ."
      ],
      "metadata": {
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Salidas y estados\n",
        "\n",
        "De forma predeterminada, la salida de una capa RNN contiene un solo vector por muestra. Este vector es la salida de la celda RNN correspondiente al último paso de tiempo, que contiene información sobre toda la secuencia de entrada. La forma de esta salida es `(batch_size, units)` donde `units` corresponde al argumento de `units` pasado al constructor de la capa.\n",
        "\n",
        "Una capa RNN también puede devolver la secuencia completa de salidas para cada muestra (un vector por paso de tiempo por muestra), si configura `return_sequences=True` . La forma de esta salida es `(batch_size, timesteps, units)` ."
      ],
      "metadata": {
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [

      ],
      "source": [
        "model = keras.Sequential()\n",
        "model.add(layers.Embedding(input_dim=1000, output_dim=64))\n",
        "\n",
        "# The output of GRU will be a 3D tensor of shape (batch_size, timesteps, 256)\n",
        "model.add(layers.GRU(256, return_sequences=True))\n",
        "\n",
        "# The output of SimpleRNN will be a 2D tensor of shape (batch_size, 128)\n",
        "model.add(layers.SimpleRNN(128))\n",
        "\n",
        "model.add(layers.Dense(10))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Además, una capa RNN puede devolver su(s) estado(s) interno(s) final(es). Los estados devueltos se pueden usar para reanudar la ejecución de RNN más tarde o [para inicializar otro RNN](https://arxiv.org/abs/1409.3215) . Esta configuración se usa comúnmente en el modelo de secuencia a secuencia codificador-decodificador, donde el estado final del codificador se usa como el estado inicial del decodificador.\n",
        "\n",
        "Para configurar una capa RNN para devolver su estado interno, establezca el parámetro `return_state` en `True` al crear la capa. Tenga en cuenta que `LSTM` tiene 2 tensores de estado, pero `GRU` solo tiene uno.\n",
        "\n",
        "Para configurar el estado inicial de la capa, simplemente llame a la capa con el argumento de palabra clave adicional `initial_state` . Tenga en cuenta que la forma del estado debe coincidir con el tamaño de la unidad de la capa, como en el ejemplo a continuación."
      ],
      "metadata": {
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [

      ],
      "source": [
        "encoder_vocab = 1000\n",
        "decoder_vocab = 2000\n",
        "\n",
        "encoder_input = layers.Input(shape=(None,))\n",
        "encoder_embedded = layers.Embedding(input_dim=encoder_vocab, output_dim=64)(\n",
        "    encoder_input\n",
        ")\n",
        "\n",
        "# Return states in addition to output\n",
        "output, state_h, state_c = layers.LSTM(64, return_state=True, name=\"encoder\")(\n",
        "    encoder_embedded\n",
        ")\n",
        "encoder_state = [state_h, state_c]\n",
        "\n",
        "decoder_input = layers.Input(shape=(None,))\n",
        "decoder_embedded = layers.Embedding(input_dim=decoder_vocab, output_dim=64)(\n",
        "    decoder_input\n",
        ")\n",
        "\n",
        "# Pass the 2 states to a new LSTM layer, as initial state\n",
        "decoder_output = layers.LSTM(64, name=\"decoder\")(\n",
        "    decoder_embedded, initial_state=encoder_state\n",
        ")\n",
        "output = layers.Dense(10)(decoder_output)\n",
        "\n",
        "model = keras.Model([encoder_input, decoder_input], output)\n",
        "model.summary()"
      ],
      "metadata": {
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Capas RNN y celdas RNN\n",
        "\n",
        "Además de las capas de RNN integradas, la API de RNN también proporciona API a nivel de celda. A diferencia de las capas RNN, que procesan lotes completos de secuencias de entrada, la celda RNN solo procesa un solo paso de tiempo.\n",
        "\n",
        "La celda es el interior del bucle `for` de una capa RNN. Envolver una celda dentro de una capa `keras.layers.RNN` le brinda una capa capaz de procesar lotes de secuencias, por ejemplo, `RNN(LSTMCell(10))` .\n",
        "\n",
        "Matemáticamente, `RNN(LSTMCell(10))` produce el mismo resultado que `LSTM(10)` . De hecho, la implementación de esta capa en TF v1.x fue simplemente crear la celda RNN correspondiente y envolverla en una capa RNN. Sin embargo, el uso de las capas `GRU` y `LSTM` integradas permite el uso de CuDNN y es posible que observe un mejor rendimiento.\n",
        "\n",
        "Hay tres celdas RNN integradas, cada una de ellas correspondiente a la capa RNN correspondiente.\n",
        "\n",
        "- `keras.layers.SimpleRNNCell` corresponde a la capa `SimpleRNN` .\n",
        "\n",
        "- `keras.layers.GRUCell` corresponde a la capa `GRU` .\n",
        "\n",
        "- `keras.layers.LSTMCell` corresponde a la capa `LSTM` .\n",
        "\n",
        "La abstracción de celdas, junto con la clase genérica `keras.layers.RNN` , hacen que sea muy fácil implementar arquitecturas RNN personalizadas para su investigación."
      ],
      "metadata": {
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Estado de lotes cruzados\n",
        "\n",
        "Al procesar secuencias muy largas (posiblemente infinitas), es posible que desee utilizar el patrón de **estado de lotes cruzados** .\n",
        "\n",
        "Normalmente, el estado interno de una capa RNN se restablece cada vez que ve un nuevo lote (es decir, se supone que cada muestra vista por la capa es independiente del pasado). La capa solo mantendrá un estado mientras procesa una muestra determinada.\n",
        "\n",
        "Sin embargo, si tiene secuencias muy largas, es útil dividirlas en secuencias más cortas y alimentar estas secuencias más cortas secuencialmente en una capa RNN sin restablecer el estado de la capa. De esa forma, la capa puede retener información sobre la totalidad de la secuencia, aunque solo vea una subsecuencia a la vez.\n",
        "\n",
        "Puede hacer esto configurando `stateful=True` en el constructor.\n",
        "\n",
        "Si tiene una secuencia `s = [t0, t1, ... t1546, t1547]` , la dividiría en, por ejemplo,\n",
        "\n",
        "```\n",
        "s1 = [t0, t1, ... t100]\n",
        "s2 = [t101, ... t201]\n",
        "...\n",
        "s16 = [t1501, ... t1547]\n",
        "```\n",
        "\n",
        "Entonces lo procesarías a través de:\n",
        "\n",
        "```python\n",
        "lstm_layer = layers.LSTM(64, stateful=True)\n",
        "for s in sub_sequences:\n",
        "  output = lstm_layer(s)\n",
        "```\n",
        "\n",
        "Cuando desee borrar el estado, puede usar `layer.reset_states()` .\n",
        "\n",
        "> Nota: En esta configuración, se supone que la muestra `i` en un lote determinado es la continuación de la muestra `i` en el lote anterior. Esto significa que todos los lotes deben contener el mismo número de muestras (tamaño de lote). Por ejemplo, si un lote contiene `[sequence_A_from_t0_to_t100, sequence_B_from_t0_to_t100]` , el siguiente lote debe contener `[sequence_A_from_t101_to_t200, sequence_B_from_t101_to_t200]` .\n",
        "\n",
        "Aquí hay un ejemplo completo:"
      ],
      "metadata": {
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [

      ],
      "source": [
        "paragraph1 = np.random.random((20, 10, 50)).astype(np.float32)\n",
        "paragraph2 = np.random.random((20, 10, 50)).astype(np.float32)\n",
        "paragraph3 = np.random.random((20, 10, 50)).astype(np.float32)\n",
        "\n",
        "lstm_layer = layers.LSTM(64, stateful=True)\n",
        "output = lstm_layer(paragraph1)\n",
        "output = lstm_layer(paragraph2)\n",
        "output = lstm_layer(paragraph3)\n",
        "\n",
        "# reset_states() will reset the cached state to the original initial_state.\n",
        "# If no initial_state was provided, zero-states will be used by default.\n",
        "lstm_layer.reset_states()\n"
      ],
      "metadata": {
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reutilización del estado RNN\n",
        "\n",
        "<a id=\"rnn_state_reuse\"></a>"
      ],
      "metadata": {
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los estados registrados de la capa RNN no se incluyen en `layer.weights()` . Si desea reutilizar el estado de una capa RNN, puede recuperar el valor de los estados por `layer.states` y usarlo como estado inicial para una nueva capa a través de la API funcional de Keras como `new_layer(inputs, initial_state=layer.states)` , o subclases de modelos.\n",
        "\n",
        "Tenga en cuenta también que es posible que no se use el modelo secuencial en este caso, ya que solo admite capas con una sola entrada y salida, la entrada adicional del estado inicial hace que no se pueda usar aquí."
      ],
      "metadata": {
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [

      ],
      "source": [
        "paragraph1 = np.random.random((20, 10, 50)).astype(np.float32)\n",
        "paragraph2 = np.random.random((20, 10, 50)).astype(np.float32)\n",
        "paragraph3 = np.random.random((20, 10, 50)).astype(np.float32)\n",
        "\n",
        "lstm_layer = layers.LSTM(64, stateful=True)\n",
        "output = lstm_layer(paragraph1)\n",
        "output = lstm_layer(paragraph2)\n",
        "\n",
        "existing_state = lstm_layer.states\n",
        "\n",
        "new_lstm_layer = layers.LSTM(64)\n",
        "new_output = new_lstm_layer(paragraph3, initial_state=existing_state)\n"
      ],
      "metadata": {
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RNN bidireccionales\n",
        "\n",
        "Para secuencias que no sean series de tiempo (por ejemplo, texto), a menudo ocurre que un modelo RNN puede funcionar mejor si no solo procesa la secuencia de principio a fin, sino también hacia atrás. Por ejemplo, para predecir la siguiente palabra en una oración, a menudo es útil tener el contexto alrededor de la palabra, no solo las palabras que la preceden.\n",
        "\n",
        "Keras proporciona una API sencilla para que pueda crear estos RNN bidireccionales: el envoltorio `keras.layers.Bidirectional` ."
      ],
      "metadata": {
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [

      ],
      "source": [
        "model = keras.Sequential()\n",
        "\n",
        "model.add(\n",
        "    layers.Bidirectional(layers.LSTM(64, return_sequences=True), input_shape=(5, 10))\n",
        ")\n",
        "model.add(layers.Bidirectional(layers.LSTM(32)))\n",
        "model.add(layers.Dense(10))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Debajo del capó, `Bidirectional` copiará la capa RNN pasada y cambiará el campo `go_backwards` de la capa recién copiada, de modo que procesará las entradas en orden inverso.\n",
        "\n",
        "La salida de la RNN `Bidirectional` será, por defecto, la concatenación de la salida de la capa de avance y la salida de la capa de retroceso. Si necesita un comportamiento de fusión diferente, por ejemplo, concatenación, cambie el parámetro `merge_mode` en el constructor de contenedor `Bidirectional` . Para obtener más detalles sobre `Bidirectional` , consulte [los documentos de la API](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Bidirectional/) ."
      ],
      "metadata": {
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimización del rendimiento y núcleos CuDNN\n",
        "\n",
        "En TensorFlow 2.0, las capas LSTM y GRU integradas se actualizaron para aprovechar los kernels CuDNN de forma predeterminada cuando hay una GPU disponible. Con este cambio, las capas `keras.layers.CuDNNLSTM/CuDNNGRU` anteriores han quedado obsoletas y puede crear su modelo sin preocuparse por el hardware en el que se ejecutará.\n",
        "\n",
        "Dado que el kernel CuDNN se crea con ciertas suposiciones, esto significa que la capa **no podrá usar el kernel CuDNN si cambia los valores predeterminados de las capas LSTM o GRU integradas** . P.ej:\n",
        "\n",
        "- Cambiando la función de `activation` de `tanh` a otra cosa.\n",
        "- `recurrent_activation` la función de activación_recurrente de `sigmoid` a otra cosa.\n",
        "- Usando `recurrent_dropout` &gt; 0.\n",
        "- Establecer `unroll` en True, lo que obliga a LSTM/GRU a descomponer el `tf.while_loop` interno en un bucle `for` desenrollado.\n",
        "- Establecer `use_bias` en falso.\n",
        "- Uso de enmascaramiento cuando los datos de entrada no se rellenan estrictamente a la derecha (si la máscara corresponde a datos rellenados estrictamente a la derecha, aún se puede usar CuDNN. Este es el caso más común).\n",
        "\n",
        "Para obtener una lista detallada de restricciones, consulte la documentación de las capas [LSTM](https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM/) y [GRU](https://www.tensorflow.org/api_docs/python/tf/keras/layers/GRU/) ."
      ],
      "metadata": {
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Usar núcleos CuDNN cuando estén disponibles\n",
        "\n",
        "Construyamos un modelo LSTM simple para demostrar la diferencia de rendimiento.\n",
        "\n",
        "Usaremos como secuencias de entrada la secuencia de filas de dígitos MNIST (tratando cada fila de píxeles como un paso de tiempo) y predeciremos la etiqueta del dígito."
      ],
      "metadata": {
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [

      ],
      "source": [
        "batch_size = 64\n",
        "# Each MNIST image batch is a tensor of shape (batch_size, 28, 28).\n",
        "# Each input sequence will be of size (28, 28) (height is treated like time).\n",
        "input_dim = 28\n",
        "\n",
        "units = 64\n",
        "output_size = 10  # labels are from 0 to 9\n",
        "\n",
        "# Build the RNN model\n",
        "def build_model(allow_cudnn_kernel=True):\n",
        "    # CuDNN is only available at the layer level, and not at the cell level.\n",
        "    # This means `LSTM(units)` will use the CuDNN kernel,\n",
        "    # while RNN(LSTMCell(units)) will run on non-CuDNN kernel.\n",
        "    if allow_cudnn_kernel:\n",
        "        # The LSTM layer with default options uses CuDNN.\n",
        "        lstm_layer = keras.layers.LSTM(units, input_shape=(None, input_dim))\n",
        "    else:\n",
        "        # Wrapping a LSTMCell in a RNN layer will not use CuDNN.\n",
        "        lstm_layer = keras.layers.RNN(\n",
        "            keras.layers.LSTMCell(units), input_shape=(None, input_dim)\n",
        "        )\n",
        "    model = keras.models.Sequential(\n",
        "        [\n",
        "            lstm_layer,\n",
        "            keras.layers.BatchNormalization(),\n",
        "            keras.layers.Dense(output_size),\n",
        "        ]\n",
        "    )\n",
        "    return model\n"
      ],
      "metadata": {
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Carguemos el conjunto de datos MNIST:"
      ],
      "metadata": {
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [

      ],
      "source": [
        "mnist = keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "sample, sample_label = x_train[0], y_train[0]"
      ],
      "metadata": {
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a crear una instancia de modelo y entrenarla.\n",
        "\n",
        "Elegimos `sparse_categorical_crossentropy` como función de pérdida para el modelo. La salida del modelo tiene la forma de `[batch_size, 10]` . El objetivo del modelo es un vector entero, cada uno de los enteros está en el rango de 0 a 9."
      ],
      "metadata": {
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [

      ],
      "source": [
        "model = build_model(allow_cudnn_kernel=True)\n",
        "\n",
        "model.compile(\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=\"sgd\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "\n",
        "model.fit(\n",
        "    x_train, y_train, validation_data=(x_test, y_test), batch_size=batch_size, epochs=1\n",
        ")"
      ],
      "metadata": {
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora, comparemos con un modelo que no usa el kernel CuDNN:"
      ],
      "metadata": {
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [

      ],
      "source": [
        "noncudnn_model = build_model(allow_cudnn_kernel=False)\n",
        "noncudnn_model.set_weights(model.get_weights())\n",
        "noncudnn_model.compile(\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=\"sgd\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "noncudnn_model.fit(\n",
        "    x_train, y_train, validation_data=(x_test, y_test), batch_size=batch_size, epochs=1\n",
        ")"
      ],
      "metadata": {
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cuando se ejecuta en una máquina con una GPU NVIDIA y CuDNN instalados, el modelo creado con CuDNN es mucho más rápido de entrenar en comparación con el modelo que usa el núcleo TensorFlow normal.\n",
        "\n",
        "El mismo modelo habilitado para CuDNN también se puede usar para ejecutar la inferencia en un entorno solo de CPU. La anotación `tf.device` continuación solo fuerza la ubicación del dispositivo. El modelo se ejecutará en la CPU de forma predeterminada si no hay una GPU disponible.\n",
        "\n",
        "Simplemente ya no tiene que preocuparse por el hardware en el que se está ejecutando. ¿No es genial?"
      ],
      "metadata": {
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [

      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "with tf.device(\"CPU:0\"):\n",
        "    cpu_model = build_model(allow_cudnn_kernel=True)\n",
        "    cpu_model.set_weights(model.get_weights())\n",
        "    result = tf.argmax(cpu_model.predict_on_batch(tf.expand_dims(sample, 0)), axis=1)\n",
        "    print(\n",
        "        \"Predicted result is: %s, target result is: %s\" % (result.numpy(), sample_label)\n",
        "    )\n",
        "    plt.imshow(sample, cmap=plt.get_cmap(\"gray\"))"
      ],
      "metadata": {
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RNN con entradas de lista/dict o entradas anidadas\n",
        "\n",
        "Las estructuras anidadas permiten a los implementadores incluir más información en un solo paso de tiempo. Por ejemplo, un cuadro de video podría tener entrada de audio y video al mismo tiempo. La forma de datos en este caso podría ser:\n",
        "\n",
        "`[batch, timestep, {\"video\": [height, width, channel], \"audio\": [frequency]}]`\n",
        "\n",
        "En otro ejemplo, los datos de escritura a mano podrían tener las coordenadas x e y para la posición actual del lápiz, así como información sobre la presión. Entonces la representación de los datos podría ser:\n",
        "\n",
        "`[batch, timestep, {\"location\": [x, y], \"pressure\": [force]}]`\n",
        "\n",
        "El siguiente código proporciona un ejemplo de cómo crear una celda RNN personalizada que acepte tales entradas estructuradas."
      ],
      "metadata": {
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Defina una celda personalizada que admita entrada/salida anidada"
      ],
      "metadata": {
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Consulte [Creación de nuevas capas y modelos a través de subclases](https://www.tensorflow.org/guide/keras/custom_layers_and_models/) para obtener detalles sobre cómo escribir sus propias capas."
      ],
      "metadata": {
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [

      ],
      "source": [
        "class NestedCell(keras.layers.Layer):\n",
        "    def __init__(self, unit_1, unit_2, unit_3, **kwargs):\n",
        "        self.unit_1 = unit_1\n",
        "        self.unit_2 = unit_2\n",
        "        self.unit_3 = unit_3\n",
        "        self.state_size = [tf.TensorShape([unit_1]), tf.TensorShape([unit_2, unit_3])]\n",
        "        self.output_size = [tf.TensorShape([unit_1]), tf.TensorShape([unit_2, unit_3])]\n",
        "        super(NestedCell, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shapes):\n",
        "        # expect input_shape to contain 2 items, [(batch, i1), (batch, i2, i3)]\n",
        "        i1 = input_shapes[0][1]\n",
        "        i2 = input_shapes[1][1]\n",
        "        i3 = input_shapes[1][2]\n",
        "\n",
        "        self.kernel_1 = self.add_weight(\n",
        "            shape=(i1, self.unit_1), initializer=\"uniform\", name=\"kernel_1\"\n",
        "        )\n",
        "        self.kernel_2_3 = self.add_weight(\n",
        "            shape=(i2, i3, self.unit_2, self.unit_3),\n",
        "            initializer=\"uniform\",\n",
        "            name=\"kernel_2_3\",\n",
        "        )\n",
        "\n",
        "    def call(self, inputs, states):\n",
        "        # inputs should be in [(batch, input_1), (batch, input_2, input_3)]\n",
        "        # state should be in shape [(batch, unit_1), (batch, unit_2, unit_3)]\n",
        "        input_1, input_2 = tf.nest.flatten(inputs)\n",
        "        s1, s2 = states\n",
        "\n",
        "        output_1 = tf.matmul(input_1, self.kernel_1)\n",
        "        output_2_3 = tf.einsum(\"bij,ijkl->bkl\", input_2, self.kernel_2_3)\n",
        "        state_1 = s1 + output_1\n",
        "        state_2_3 = s2 + output_2_3\n",
        "\n",
        "        output = (output_1, output_2_3)\n",
        "        new_states = (state_1, state_2_3)\n",
        "\n",
        "        return output, new_states\n",
        "\n",
        "    def get_config(self):\n",
        "        return {\"unit_1\": self.unit_1, \"unit_2\": unit_2, \"unit_3\": self.unit_3}\n"
      ],
      "metadata": {
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cree un modelo RNN con entrada/salida anidada\n",
        "\n",
        "Construyamos un modelo Keras que use una capa `keras.layers.RNN` y la celda personalizada que acabamos de definir."
      ],
      "metadata": {
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [

      ],
      "source": [
        "unit_1 = 10\n",
        "unit_2 = 20\n",
        "unit_3 = 30\n",
        "\n",
        "i1 = 32\n",
        "i2 = 64\n",
        "i3 = 32\n",
        "batch_size = 64\n",
        "num_batches = 10\n",
        "timestep = 50\n",
        "\n",
        "cell = NestedCell(unit_1, unit_2, unit_3)\n",
        "rnn = keras.layers.RNN(cell)\n",
        "\n",
        "input_1 = keras.Input((None, i1))\n",
        "input_2 = keras.Input((None, i2, i3))\n",
        "\n",
        "outputs = rnn((input_1, input_2))\n",
        "\n",
        "model = keras.models.Model([input_1, input_2], outputs)\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Entrena el modelo con datos generados aleatoriamente\n",
        "\n",
        "Dado que no hay un buen conjunto de datos candidato para este modelo, usamos datos Numpy aleatorios para la demostración."
      ],
      "metadata": {
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [

      ],
      "source": [
        "input_1_data = np.random.random((batch_size * num_batches, timestep, i1))\n",
        "input_2_data = np.random.random((batch_size * num_batches, timestep, i2, i3))\n",
        "target_1_data = np.random.random((batch_size * num_batches, unit_1))\n",
        "target_2_data = np.random.random((batch_size * num_batches, unit_2, unit_3))\n",
        "input_data = [input_1_data, input_2_data]\n",
        "target_data = [target_1_data, target_2_data]\n",
        "\n",
        "model.fit(input_data, target_data, batch_size=batch_size)"
      ],
      "metadata": {
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the Keras `keras.layers.RNN` layer, You are only expected to define the math logic for individual step within the sequence, and the `keras.layers.RNN` layer will handle the sequence iteration for you. It's an incredibly powerful way to quickly prototype new kinds of RNNs (e.g. a LSTM variant).\n",
        "\n",
        "Para obtener más detalles, visite los [documentos de la API](https://https://www.tensorflow.org/api_docs/python/tf/keras/layers/RNN/) ."
      ],
      "metadata": {
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [

      ],
      "name": "rnn.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

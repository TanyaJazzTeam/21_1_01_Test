{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##### Copyright 2018 Los autores de TensorFlow."
      ],
      "metadata": {
      }
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "outputs": [

      ],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "metadata": {
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using the SavedModel format"
      ],
      "metadata": {
      }
    },
      {
      "cell_type": "markdown",
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td><a target=\"_blank\" href=\"https://www.tensorflow.org/guide/saved_model\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">Ver en TensorFlow.org</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/guide/saved_model.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Ejecutar en Google Colab</a></td>\n",
        "  <td><a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/guide/saved_model.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">Ver fuente en GitHub</a></td>\n",
        "  <td><a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/guide/saved_model.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">Descargar libreta</a></td>\n",
        "</table>"
      ],
      "metadata": {
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Un modelo guardado contiene un programa TensorFlow completo, incluidos pesos y cálculos. No requiere el código de creación del modelo original para ejecutarse, lo que lo hace útil para compartir o implementar (con [TFLite](https://tensorflow.org/lite) , [TensorFlow.js](https://js.tensorflow.org/) , [TensorFlow Serving](https://www.tensorflow.org/tfx/serving/tutorials/Serving_REST_simple) o [TensorFlow Hub](https://tensorflow.org/hub) ).\n",
        "\n",
        "Este documento se sumerge en algunos de los detalles de cómo usar la API `tf.saved_model` de bajo nivel:\n",
        "\n",
        "- Si está utilizando un `tf.keras.Model` , el `keras.Model.save(output_path)` puede ser todo lo que necesita: vea [Keras guardar y serializar](keras/save_and_serialize.ipynb)\n",
        "\n",
        "- If you just want to save/load weights during training see the [guide to training checkpoints](./checkpoint.ipynb).\n"
      ],
      "metadata": {
      }
    },
        {
      "cell_type": "code",
      "execution_count": 0,
      "outputs": [

      ],
      "source": [
        "import os\n",
        "import tempfile\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "tmpdir = tempfile.mkdtemp()"
      ],
      "metadata": {
      }
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "outputs": [

      ],
      "source": [
        "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "if physical_devices:\n",
        "  tf.config.experimental.set_memory_growth(physical_devices[0], True)"
      ],
      "metadata": {
      }
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "outputs": [

      ],
      "source": [
        "file = tf.keras.utils.get_file(\n",
        "    \"grace_hopper.jpg\",\n",
        "    \"https://storage.googleapis.com/download.tensorflow.org/example_images/grace_hopper.jpg\")\n",
        "img = tf.keras.preprocessing.image.load_img(file, target_size=[224, 224])\n",
        "plt.imshow(img)\n",
        "plt.axis('off')\n",
        "x = tf.keras.preprocessing.image.img_to_array(img)\n",
        "x = tf.keras.applications.mobilenet.preprocess_input(\n",
        "    x[tf.newaxis,...])"
      ],
      "metadata": {
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"saved_model_cli\"></a>\n",
        "\n",
        "## Detalles de la interfaz de línea de comandos de SavedModel\n",
        "\n",
        "Puede utilizar la interfaz de línea de comandos (CLI) del modelo guardado para inspeccionar y ejecutar un modelo guardado. Por ejemplo, puede usar la CLI para inspeccionar los `SignatureDef` del modelo. La CLI le permite confirmar rápidamente que el tipo y la forma del tensor de entrada coinciden con el modelo. Además, si desea probar su modelo, puede usar la CLI para realizar una verificación de cordura al pasar entradas de muestra en varios formatos (por ejemplo, expresiones de Python) y luego obtener la salida.\n",
        "\n",
        "### Instale la CLI del modelo guardado\n",
        "\n",
        "En términos generales, puede instalar TensorFlow de cualquiera de las dos formas siguientes:\n",
        "\n",
        "- Al instalar un binario de TensorFlow preconstruido.\n",
        "- Construyendo TensorFlow a partir del código fuente.\n",
        "\n",
        "Si instaló TensorFlow a través de un binario de TensorFlow prediseñado, entonces la CLI del modelo guardado ya está instalada en su sistema en el nombre de ruta `bin/saved_model_cli` .\n",
        "\n",
        "Si compilaste TensorFlow a partir del código fuente, debes ejecutar el siguiente comando adicional para compilar `saved_model_cli` :\n",
        "\n",
        "```\n",
        "$ bazel build tensorflow/python/tools:saved_model_cli\n",
        "```\n",
        "\n",
        "### Descripción general de los comandos\n",
        "\n",
        "La CLI del modelo guardado admite los siguientes dos comandos en un modelo guardado:\n",
        "\n",
        "- `show` , que muestra los cálculos disponibles de un modelo guardado.\n",
        "- `run` , que ejecuta un cálculo desde un modelo guardado.\n",
        "\n",
        "### `show` comando\n",
        "\n",
        "Un modelo guardado contiene una o más variantes de modelo (técnicamente, `v1.MetaGraphDef` s), identificadas por sus conjuntos de etiquetas. Para servir un modelo, es posible que se pregunte qué tipo de `SignatureDef` hay en cada variante del modelo y cuáles son sus entradas y salidas. El comando `show` le permite examinar el contenido del modelo guardado en orden jerárquico. Aquí está la sintaxis:\n",
        "\n",
        "```\n",
        "usage: saved_model_cli show [-h] --dir DIR [--all]\n",
        "[--tag_set TAG_SET] [--signature_def SIGNATURE_DEF_KEY]\n",
        "```\n",
        "\n",
        "Por ejemplo, el siguiente comando muestra todos los conjuntos de etiquetas disponibles en el modelo guardado:\n",
        "\n",
        "```\n",
        "$ saved_model_cli show --dir /tmp/saved_model_dir\n",
        "The given SavedModel contains the following tag-sets:\n",
        "serve\n",
        "serve, gpu\n",
        "```\n",
        "\n",
        "El siguiente comando muestra todas las claves `SignatureDef` disponibles para un conjunto de etiquetas:\n",
        "\n",
        "```\n",
        "$ saved_model_cli show --dir /tmp/saved_model_dir --tag_set serve\n",
        "The given SavedModel `MetaGraphDef` contains `SignatureDefs` with the\n",
        "following keys:\n",
        "SignatureDef key: \"classify_x2_to_y3\"\n",
        "SignatureDef key: \"classify_x_to_y\"\n",
        "SignatureDef key: \"regress_x2_to_y3\"\n",
        "SignatureDef key: \"regress_x_to_y\"\n",
        "SignatureDef key: \"regress_x_to_y2\"\n",
        "SignatureDef key: \"serving_default\"\n",
        "```\n",
        "\n",
        "Si hay *varias* etiquetas en el conjunto de etiquetas, debe especificar todas las etiquetas, cada etiqueta separada por una coma. Por ejemplo:\n",
        "\n",
        "<pre>\n",
        "$ saved_model_cli show --dir /tmp/saved_model_dir --tag_set serve,gpu\n",
        "</pre>\n",
        "\n",
        "Para mostrar todas las entradas y salidas de TensorInfo para un `SignatureDef` específico, pase la clave `SignatureDef` a la opción `signature_def` . Esto es muy útil cuando desea conocer el valor de la clave del tensor, el tipo y la forma de los tensores de entrada para ejecutar el gráfico de cálculo más adelante. Por ejemplo:\n",
        "\n",
        "```\n",
        "$ saved_model_cli show --dir \\\n",
        "/tmp/saved_model_dir --tag_set serve --signature_def serving_default\n",
        "The given SavedModel SignatureDef contains the following input(s):\n",
        "  inputs['x'] tensor_info:\n",
        "      dtype: DT_FLOAT\n",
        "      shape: (-1, 1)\n",
        "      name: x:0\n",
        "The given SavedModel SignatureDef contains the following output(s):\n",
        "  outputs['y'] tensor_info:\n",
        "      dtype: DT_FLOAT\n",
        "      shape: (-1, 1)\n",
        "      name: y:0\n",
        "Method name is: tensorflow/serving/predict\n",
        "```\n",
        "\n",
        "Para mostrar toda la información disponible en el modelo guardado, use la opción `--all` . Por ejemplo:\n",
        "\n",
        "<pre>\n",
        "$ saved_model_cli show --dir /tmp/saved_model_dir --all\n",
        "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
        "\n",
        "signature_def['classify_x2_to_y3']:\n",
        "  The given SavedModel SignatureDef contains the following input(s):\n",
        "    inputs['inputs'] tensor_info:\n",
        "        dtype: DT_FLOAT\n",
        "        shape: (-1, 1)\n",
        "        name: x2:0\n",
        "  The given SavedModel SignatureDef contains the following output(s):\n",
        "    outputs['scores'] tensor_info:\n",
        "        dtype: DT_FLOAT\n",
        "        shape: (-1, 1)\n",
        "        name: y3:0\n",
        "  Method name is: tensorflow/serving/classify\n",
        "\n",
        "...\n",
        "\n",
        "signature_def['serving_default']:\n",
        "  The given SavedModel SignatureDef contains the following input(s):\n",
        "    inputs['x'] tensor_info:\n",
        "        dtype: DT_FLOAT\n",
        "        shape: (-1, 1)\n",
        "        name: x:0\n",
        "  The given SavedModel SignatureDef contains the following output(s):\n",
        "    outputs['y'] tensor_info:\n",
        "        dtype: DT_FLOAT\n",
        "        shape: (-1, 1)\n",
        "        name: y:0\n",
        "  Method name is: tensorflow/serving/predict\n",
        "</pre>\n",
        "\n",
        "### `run` comando\n",
        "\n",
        "Invoque el comando de `run` para ejecutar un cálculo gráfico, pasando entradas y luego mostrando (y opcionalmente guardando) las salidas. Aquí está la sintaxis:\n",
        "\n",
        "```\n",
        "usage: saved_model_cli run [-h] --dir DIR --tag_set TAG_SET --signature_def\n",
        "                           SIGNATURE_DEF_KEY [--inputs INPUTS]\n",
        "                           [--input_exprs INPUT_EXPRS]\n",
        "                           [--input_examples INPUT_EXAMPLES] [--outdir OUTDIR]\n",
        "                           [--overwrite] [--tf_debug]\n",
        "```\n",
        "\n",
        "El comando `run` proporciona las siguientes tres formas de pasar entradas al modelo:\n",
        "\n",
        "- La opción `--inputs` le permite pasar numpy ndarray en archivos.\n",
        "- La opción `--input_exprs` le permite pasar expresiones de Python.\n",
        "- La opción `--input_examples` le permite pasar `tf.train.Example` .\n",
        "\n",
        "#### `--inputs`\n",
        "\n",
        "Para pasar datos de entrada en archivos, especifique la opción `--inputs` , que toma el siguiente formato general:\n",
        "\n",
        "```bsh\n",
        "--inputs &lt;INPUTS&gt;\n",
        "```\n",
        "\n",
        "donde *ENTRADAS* es cualquiera de los siguientes formatos:\n",
        "\n",
        "- `&lt;input_key&gt;=&lt;filename&gt;`\n",
        "- `&lt;input_key&gt;=&lt;filename&gt;[&lt;variable_name&gt;]`\n",
        "\n",
        "Puede pasar varias *ENTRADAS* . Si pasa varias entradas, use un punto y coma para separar cada una de las *ENTRADAS* .\n",
        "\n",
        "`saved_model_cli` usa `numpy.load` para cargar el nombre de *archivo* . El nombre del *archivo* puede estar en cualquiera de los siguientes formatos:\n",
        "\n",
        "- `.npy`\n",
        "- `.npz`\n",
        "- formato de pepinillo\n",
        "\n",
        "Un archivo `.npy` siempre contiene un ndarray numpy. Por lo tanto, al cargar desde un archivo `.npy` , el contenido se asignará directamente al tensor de entrada especificado. Si especifica un *nombre_variable* con ese archivo `.npy` , el *nombre_variable* se ignorará y se emitirá una advertencia.\n",
        "\n",
        "Al cargar desde un `.npz` (zip), puede especificar opcionalmente un nombre_variable para identificar la *variable* dentro del archivo zip para cargar la clave de tensor de entrada. Si no especifica un *nombre_variable* , la CLI del modelo guardado verificará que solo se incluye un archivo en el archivo zip y lo cargará para la clave de tensor de entrada especificada.\n",
        "\n",
        "Al cargar desde un archivo pickle, si no se especifica ningún `variable_name` entre corchetes, lo que sea que esté dentro del archivo pickle se pasará a la clave de tensor de entrada especificada. De lo contrario, la CLI del modelo guardado supondrá que hay un diccionario almacenado en el archivo pickle y se usará el valor correspondiente a *variable_name* .\n",
        "\n",
        "#### `--input_exprs`\n",
        "\n",
        "Para pasar entradas a través de expresiones de Python, especifique la opción `--input_exprs` . Esto puede ser útil cuando no tiene archivos de datos por ahí, pero aún desea verificar la cordura del modelo con algunas entradas simples que coinciden con el tipo de d y la forma de los `SignatureDef` s del modelo. Por ejemplo:\n",
        "\n",
        "```bsh\n",
        "`&lt;input_key&gt;=[[1],[2],[3]]`\n",
        "```\n",
        "\n",
        "Además de las expresiones de Python, también puede pasar funciones numpy. Por ejemplo:\n",
        "\n",
        "```bsh\n",
        "`&lt;input_key&gt;=np.ones((32,32,3))`\n",
        "```\n",
        "\n",
        "(Tenga en cuenta que el módulo `numpy` ya está disponible para usted como `np` ).\n",
        "\n",
        "#### `--input_examples`\n",
        "\n",
        "Para pasar `tf.train.Example` como entradas, especifique la opción `--input_examples` . Para cada tecla de entrada, toma una lista de diccionarios, donde cada diccionario es una instancia de `tf.train.Example` . Las claves del diccionario son las funciones y los valores son las listas de valores para cada función. Por ejemplo:\n",
        "\n",
        "```bsh\n",
        "`&lt;input_key&gt;=[{\"age\":[22,24],\"education\":[\"BS\",\"MS\"]}]`\n",
        "```\n",
        "\n",
        "#### Guardar salida\n",
        "\n",
        "De forma predeterminada, la CLI del modelo guardado escribe la salida en la salida estándar. Si se pasa un directorio a la opción `--outdir` , las salidas se guardarán como archivos `.npy` con el nombre de las claves de tensor de salida en el directorio dado.\n",
        "\n",
        "Utilice `--overwrite` para sobrescribir los archivos de salida existentes.\n"
      ],
      "metadata": {
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [

      ],
      "name": "saved_model.ipynb",
      "private_outputs": true,
      "provenance": [

      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

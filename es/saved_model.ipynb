{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##### Copyright 2018 Los autores de TensorFlow."
      ],
      "metadata": {
      }
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "outputs": [

      ],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "metadata": {
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using the SavedModel format"
      ],
      "metadata": {
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/guide/saved_model\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/guide/saved_model.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/guide/saved_model.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/guide/saved_model.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "</table>"
      ],
      "metadata": {
        "id": "gl_2r04ARt6ti"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Un modelo guardado contiene un programa TensorFlow completo, incluidos pesos y cálculos. No requiere el código de creación del modelo original para ejecutarse, lo que lo hace útil para compartir o implementar (con [TFLite](https://tensorflow.org/lite) , [TensorFlow.js](https://js.tensorflow.org/) , [TensorFlow Serving](https://www.tensorflow.org/tfx/serving/tutorials/Serving_REST_simple) o [TensorFlow Hub](https://tensorflow.org/hub) ).\n",
        "\n",
        "This document dives into some of the details of how to use the low-level `tf.saved_model` api:\n",
        "\n",
        "- If you are using a `tf.keras.Model` the `keras.Model.save(output_path)` method may be all you need: See the [Keras save and serialize](keras/save_and_serialize.ipynb)\n",
        "\n",
        "- If you just want to save/load weights during training see the [guide to training checkpoints](./checkpoint.ipynb).\n"
      ],
      "metadata": {
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a SavedModel from Keras\n",
        "\n",
        "For a quick introduction, this section exports a pre-trained Keras model and serves image classification requests with it. The rest of the guide will fill in details and discuss other ways to create SavedModels."
      ],
      "metadata": {
        "id": "gl_ObpsixwVUo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "outputs": [

      ],
      "source": [
        "import os\n",
        "import tempfile\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "tmpdir = tempfile.mkdtemp()"
      ],
      "metadata": {
      }
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "outputs": [

      ],
      "source": [
        "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "if physical_devices:\n",
        "  tf.config.experimental.set_memory_growth(physical_devices[0], True)"
      ],
      "metadata": {
      }
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "outputs": [

      ],
      "source": [
        "file = tf.keras.utils.get_file(\n",
        "    \"grace_hopper.jpg\",\n",
        "    \"https://storage.googleapis.com/download.tensorflow.org/example_images/grace_hopper.jpg\")\n",
        "img = tf.keras.preprocessing.image.load_img(file, target_size=[224, 224])\n",
        "plt.imshow(img)\n",
        "plt.axis('off')\n",
        "x = tf.keras.preprocessing.image.img_to_array(img)\n",
        "x = tf.keras.applications.mobilenet.preprocess_input(\n",
        "    x[tf.newaxis,...])"
      ],
      "metadata": {
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id=\"saved_model_cli\"></a>\n",
        "\n",
        "## Details of the SavedModel command line interface\n",
        "\n",
        "You can use the SavedModel Command Line Interface (CLI) to inspect and execute a SavedModel. For example, you can use the CLI to inspect the model's `SignatureDef`s. The CLI enables you to quickly confirm that the input Tensor dtype and shape match the model. Moreover, if you want to test your model, you can use the CLI to do a sanity check by passing in sample inputs in various formats (for example, Python expressions) and then fetching the output.\n",
        "\n",
        "### Install the SavedModel CLI\n",
        "\n",
        "Broadly speaking, you can install TensorFlow in either of the following two ways:\n",
        "\n",
        "- By installing a pre-built TensorFlow binary.\n",
        "- By building TensorFlow from source code.\n",
        "\n",
        "If you installed TensorFlow through a pre-built TensorFlow binary, then the SavedModel CLI is already installed on your system at pathname `bin/saved_model_cli`.\n",
        "\n",
        "If you built TensorFlow from source code, you must run the following additional command to build `saved_model_cli`:\n",
        "\n",
        "```\n",
        "$ bazel build tensorflow/python/tools:saved_model_cli\n",
        "```\n",
        "\n",
        "### Overview of commands\n",
        "\n",
        "The SavedModel CLI supports the following two commands on a SavedModel:\n",
        "\n",
        "- `show`, which shows the computations available from a SavedModel.\n",
        "- `run`, which runs a computation from a SavedModel.\n",
        "\n",
        "### `show` command\n",
        "\n",
        "A SavedModel contains one or more model variants (technically, `v1.MetaGraphDef`s), identified by their tag-sets. To serve a model, you might wonder what kind of `SignatureDef`s are in each model variant, and what are their inputs and outputs.  The `show` command let you examine the contents of the SavedModel in hierarchical order.  Here's the syntax:\n",
        "\n",
        "```\n",
        "usage: saved_model_cli show [-h] --dir DIR [--all]\n",
        "[--tag_set TAG_SET] [--signature_def SIGNATURE_DEF_KEY]\n",
        "```\n",
        "\n",
        "For example, the following command shows all available tag-sets in the SavedModel:\n",
        "\n",
        "```\n",
        "$ saved_model_cli show --dir /tmp/saved_model_dir\n",
        "The given SavedModel contains the following tag-sets:\n",
        "serve\n",
        "serve, gpu\n",
        "```\n",
        "\n",
        "The following command shows all available `SignatureDef` keys for a tag set:\n",
        "\n",
        "```\n",
        "$ saved_model_cli show --dir /tmp/saved_model_dir --tag_set serve\n",
        "The given SavedModel `MetaGraphDef` contains `SignatureDefs` with the\n",
        "following keys:\n",
        "SignatureDef key: \"classify_x2_to_y3\"\n",
        "SignatureDef key: \"classify_x_to_y\"\n",
        "SignatureDef key: \"regress_x2_to_y3\"\n",
        "SignatureDef key: \"regress_x_to_y\"\n",
        "SignatureDef key: \"regress_x_to_y2\"\n",
        "SignatureDef key: \"serving_default\"\n",
        "```\n",
        "\n",
        "If there are *multiple* tags in the tag-set, you must specify all tags, each tag separated by a comma. For example:\n",
        "\n",
        "<pre>\n",
        "$ saved_model_cli show --dir /tmp/saved_model_dir --tag_set serve,gpu\n",
        "</pre>\n",
        "\n",
        "To show all inputs and outputs TensorInfo for a specific `SignatureDef`, pass in the `SignatureDef` key to `signature_def` option. This is very useful when you want to know the tensor key value, dtype and shape of the input tensors for executing the computation graph later. For example:\n",
        "\n",
        "```\n",
        "$ saved_model_cli show --dir \\\n",
        "/tmp/saved_model_dir --tag_set serve --signature_def serving_default\n",
        "The given SavedModel SignatureDef contains the following input(s):\n",
        "  inputs['x'] tensor_info:\n",
        "      dtype: DT_FLOAT\n",
        "      shape: (-1, 1)\n",
        "      name: x:0\n",
        "The given SavedModel SignatureDef contains the following output(s):\n",
        "  outputs['y'] tensor_info:\n",
        "      dtype: DT_FLOAT\n",
        "      shape: (-1, 1)\n",
        "      name: y:0\n",
        "Method name is: tensorflow/serving/predict\n",
        "```\n",
        "\n",
        "To show all available information in the SavedModel, use the `--all` option. For example:\n",
        "\n",
        "<pre>\n",
        "$ saved_model_cli show --dir /tmp/saved_model_dir --all\n",
        "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
        "\n",
        "signature_def['classify_x2_to_y3']:\n",
        "  The given SavedModel SignatureDef contains the following input(s):\n",
        "    inputs['inputs'] tensor_info:\n",
        "        dtype: DT_FLOAT\n",
        "        shape: (-1, 1)\n",
        "        name: x2:0\n",
        "  The given SavedModel SignatureDef contains the following output(s):\n",
        "    outputs['scores'] tensor_info:\n",
        "        dtype: DT_FLOAT\n",
        "        shape: (-1, 1)\n",
        "        name: y3:0\n",
        "  Method name is: tensorflow/serving/classify\n",
        "\n",
        "...\n",
        "\n",
        "signature_def['serving_default']:\n",
        "  The given SavedModel SignatureDef contains the following input(s):\n",
        "    inputs['x'] tensor_info:\n",
        "        dtype: DT_FLOAT\n",
        "        shape: (-1, 1)\n",
        "        name: x:0\n",
        "  The given SavedModel SignatureDef contains the following output(s):\n",
        "    outputs['y'] tensor_info:\n",
        "        dtype: DT_FLOAT\n",
        "        shape: (-1, 1)\n",
        "        name: y:0\n",
        "  Method name is: tensorflow/serving/predict\n",
        "</pre>\n",
        "\n",
        "### `run` command\n",
        "\n",
        "Invoke the `run` command to run a graph computation, passing inputs and then displaying (and optionally saving) the outputs. Here's the syntax:\n",
        "\n",
        "```\n",
        "usage: saved_model_cli run [-h] --dir DIR --tag_set TAG_SET --signature_def\n",
        "                           SIGNATURE_DEF_KEY [--inputs INPUTS]\n",
        "                           [--input_exprs INPUT_EXPRS]\n",
        "                           [--input_examples INPUT_EXAMPLES] [--outdir OUTDIR]\n",
        "                           [--overwrite] [--tf_debug]\n",
        "```\n",
        "\n",
        "The `run` command provides the following three ways to pass inputs to the model:\n",
        "\n",
        "- `--inputs` option enables you to pass numpy ndarray in files.\n",
        "- `--input_exprs` option enables you to pass Python expressions.\n",
        "- `--input_examples` option enables you to pass `tf.train.Example`.\n",
        "\n",
        "#### `--inputs`\n",
        "\n",
        "To pass input data in files, specify the `--inputs` option, which takes the following general format:\n",
        "\n",
        "```bsh\n",
        "--inputs &lt;INPUTS&gt;\n",
        "```\n",
        "\n",
        "where *INPUTS* is either of the following formats:\n",
        "\n",
        "- `&lt;input_key&gt;=&lt;filename&gt;`\n",
        "- `&lt;input_key&gt;=&lt;filename&gt;[&lt;variable_name&gt;]`\n",
        "\n",
        "You may pass multiple *INPUTS*. If you do pass multiple inputs, use a semicolon to separate each of the *INPUTS*.\n",
        "\n",
        "`saved_model_cli` uses `numpy.load` to load the *filename*. The *filename* may be in any of the following formats:\n",
        "\n",
        "- `.npy`\n",
        "- `.npz`\n",
        "- pickle format\n",
        "\n",
        "A `.npy` file always contains a numpy ndarray. Therefore, when loading from a `.npy` file, the content will be directly assigned to the specified input tensor. If you specify a *variable_name* with that `.npy` file, the *variable_name* will be ignored and a warning will be issued.\n",
        "\n",
        "When loading from a `.npz` (zip) file, you may optionally specify a *variable_name* to identify the variable within the zip file to load for the input tensor key.  If you don't specify a *variable_name*, the SavedModel CLI will check that only one file is included in the zip file and load it for the specified input tensor key.\n",
        "\n",
        "When loading from a pickle file, if no `variable_name` is specified in the square brackets, whatever that is inside the pickle file will be passed to the specified input tensor key. Otherwise, the SavedModel CLI will assume a dictionary is stored in the pickle file and the value corresponding to the *variable_name* will be used.\n",
        "\n",
        "#### `--input_exprs`\n",
        "\n",
        "To pass inputs through Python expressions, specify the `--input_exprs` option. This can be useful for when you don't have data files lying around, but still want to sanity check the model with some simple inputs that match the dtype and shape of the model's `SignatureDef`s. For example:\n",
        "\n",
        "```bsh\n",
        "`&lt;input_key&gt;=[[1],[2],[3]]`\n",
        "```\n",
        "\n",
        "In addition to Python expressions, you may also pass numpy functions. For example:\n",
        "\n",
        "```bsh\n",
        "`&lt;input_key&gt;=np.ones((32,32,3))`\n",
        "```\n",
        "\n",
        "(Note that the `numpy` module is already available to you as `np`.)\n",
        "\n",
        "#### `--input_examples`\n",
        "\n",
        "To pass `tf.train.Example` as inputs, specify the `--input_examples` option. For each input key, it takes a list of dictionary, where each dictionary is an instance of `tf.train.Example`. The dictionary keys are the features and the values are the value lists for each feature. For example:\n",
        "\n",
        "```bsh\n",
        "`&lt;input_key&gt;=[{\"age\":[22,24],\"education\":[\"BS\",\"MS\"]}]`\n",
        "```\n",
        "\n",
        "#### Save output\n",
        "\n",
        "By default, the SavedModel CLI writes output to stdout. If a directory is passed to `--outdir` option, the outputs will be saved as `.npy` files named after output tensor keys under the given directory.\n",
        "\n",
        "Use `--overwrite` to overwrite existing output files.\n"
      ],
      "metadata": {
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [

      ],
      "name": "saved_model.ipynb",
      "private_outputs": true,
      "provenance": [

      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
